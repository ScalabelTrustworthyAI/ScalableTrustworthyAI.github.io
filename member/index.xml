<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Members on Scalable Trustworthy AI</title><link>https://ScalableTrustworthyAI.github.io/member/</link><description>Recent content in Members on Scalable Trustworthy AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&amp;copy; Seong Joon Oh, 2023</copyright><lastBuildDate>Mon, 29 Jan 2024 19:50:20 +0200</lastBuildDate><atom:link href="https://ScalableTrustworthyAI.github.io/member/index.xml" rel="self" type="application/rss+xml"/><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/stefano/</link><pubDate>Mon, 29 Jan 2024 19:50:20 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/stefano/</guid><description>I am a PhD student in the International Max-Planck Research School for Intelligent Systems (IMPRS-IS), supervised by Christian Baumgartner and co-supervised by Seong Joon Oh at the University of Tübingen.
I work on few-shot learning and domain generalisation for medical image analysis. I am passionate about developing more “human-like” machine learning methods, which mimic our ability to make predictions based on a limited number of training examples and to generalise to unsee tasks.</description></item><item><title>Arnas Uselis | PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/arnas/</link><pubDate>Mon, 24 Jul 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/arnas/</guid><description>I&amp;rsquo;m a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (IMPRS-IS), under the supervision of Seong Joon Oh.
I&amp;rsquo;m primarily interested in enhancing the generalization capabilities of current machine learning systems. This involves learning robust representations from raw data and using them in a way that accurately reflects data generative processes. I believe that mimicking the structure of the real-world in our models, both in how we learn representations and in how we use them, is a key part of making progress towards trustworthy systems.</description></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/evgenii/</link><pubDate>Sat, 17 Jun 2023 13:06:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/evgenii/</guid><description>My personal page is at kortukov.github.io.
I am currently pursuing my MSc degree in Machine Learning at the University of Tübingen, supervised by Seong Joon Oh, Elisa Nguyen and Alexander Rubinstein. My research interests primarily revolve around mitigating the risks associated with increasingly powerful ML systems. My current focus involves exploring data-driven explainability methods and their application to language models.
I receieved my Bachelor degree in Computer Science from Lomonosov Moscow State University in 2020.</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/balint/</link><pubDate>Fri, 02 Jun 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/balint/</guid><description>I am a Machine Learning MSc student at the University of Tübingen, supervised by Seong Joon Oh, Michael Kirchhof, and Alexander Rubinstein.
I am interested in model architectures capable of representing different sources of uncertainty. My goal is to contribute to the theoretical foundations of uncertainty in machine learning while developing scalable practical solutions.
I received my BSc degree in Computer Science from ELTE Eötvös Loránd University in 2021 with the Outstanding Student of the Faculty award.</description></item><item><title>Collaborating PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/michael/</link><pubDate>Fri, 31 Mar 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/michael/</guid><description>I&amp;rsquo;m a PhD student in the International Max-Planck Research School for Intelligent Systems (IMPRS-IS), co-supervised by Enkelejda Kasneci and Seong Joon Oh at the University of Tübingen.
My goal is making machine learning more trustworthy by delivering pretrained uncertainty estimates along with each prediction. To this end, I&amp;rsquo;m developing probabilistic embeddings that represent a model&amp;rsquo;s uncertainty directly in its embedding space. I love to understand and prove things first from a theoretical perspective first (like MCInfoNCE) and then scale them to large datasets as in the new URL benchmark.</description></item><item><title>Group Leader</title><link>https://ScalableTrustworthyAI.github.io/member/joon/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/joon/</guid><description>My personal page is at seongjoonoh.com.
I am an independent group leader at the Tübingen AI Center at the University of Tübingen, where I lead the group on Scalable Trustworthy AI (STAI). I am interested in training reliable models (e.g. explainable, robust, and probabilistic models) and obtaining the necessary human supervision and guidance in a cost-effective way.
I have been a research scientist at NAVER AI Lab for 3.5 years. I received my PhD in computer vision and machine learning at Max-Planck Institute for Informatics in 2018, under the supervision of Bernt Schiele and Mario Fritz.</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/alex/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/alex/</guid><description>I am a PhD Student at the Tübingen AI Center at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (IMPRS-IS), where I work in the group on Scalable Trustworthy AI (STAI). I am interested in researching the ways of making models not only perfectly classify MNIST but also not fail too much on real world tasks. In case possibilities of some models are limited to academic datasets, I want to understand why that is the case.</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elif/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elif/</guid><description>I am a first year PhD student in the Scalable Trustworthy AI (STAI) group at the Tübingen AI Center.
I received my Master’s degree in Computer Science from University of Tübingen in 2022, and Bachelor’s in Computer Science from Saarland University in 2019. I am interested in understanding abstractions humans and neural networks perform in visual representations and how to use these to improve model robustness and Human-Computer Interaction.</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elisa/</link><pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elisa/</guid><description>My personal page is at elisanguyen.github.io.
I am a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (IMPRS-IS). My research focus is on exploring training data attribution as a means of helping humans understand model behavior.
I absolved my Master’s in Interaction Technology at the University of Twente and my Bachelor’s in Computer Science and Management at the Nordakademie. I did my Bachelor studies in a dual study format in cooperation with Airbus, where I also worked for about 2.</description></item></channel></rss>