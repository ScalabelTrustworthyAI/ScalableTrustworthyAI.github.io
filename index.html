<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.115.4"><script async src="https://www.googletagmanager.com/gtag/js?id=G-RF7RQJFKWW"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RF7RQJFKWW")</script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=theme content="hugo-academic-group"><script src=https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js></script>
<script src=https://ScalableTrustworthyAI.github.io/js/hugo-academic-group.js></script>
<link rel=stylesheet href=https://ScalableTrustworthyAI.github.io/css/bootstrap.min.css><script src=https://ScalableTrustworthyAI.github.io/js/bootstrap.min.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/default.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.2/gh-fork-ribbon.min.css><script src=https://ScalableTrustworthyAI.github.io/js/highlight.pack.js></script>
<script>hljs.initHighlightingOnLoad()</script><link rel=stylesheet href=https://ScalableTrustworthyAI.github.io/css/font-awesome.min.css><link rel=stylesheet href=https://ScalableTrustworthyAI.github.io/css/academicons.min.css><link rel=stylesheet href="//fonts.googleapis.com/css?family=Lato:100,300,400,700|Merriweather:100,400,700|Roboto+Mono"><link rel=stylesheet href=https://ScalableTrustworthyAI.github.io/css/hugo-academic-group.css><link rel="shortcut icon" href=https://ScalableTrustworthyAI.github.io/img/favicon.png type=image/x-icon><link rel=canonical href=https://ScalableTrustworthyAI.github.io/><title>Scalable Trustworthy AI</title></head><body><div class=home-anchor id=home></div><nav class="navbar navbar-default navbar-fixed-top" id=navbar-main><div class=container><div class=navbar-header><button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=.navbar-collapse aria-expanded=false>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button><div class=navbar-brand><a class=logo href=https://ScalableTrustworthyAI.github.io/><img src=https://ScalableTrustworthyAI.github.io/img/stai_logo.png alt="Research group logo"></img></a></div></div><div class="collapse navbar-collapse" id=#navbar-collapse-1><ul class="nav navbar-nav navbar-right"><li class=nav-item><a data-scroll href=https://ScalableTrustworthyAI.github.io/#top>Home</a></li><li class=nav-item><a data-scroll href=https://ScalableTrustworthyAI.github.io/#overview>Overview</a></li><li class=nav-item><a data-scroll href=https://ScalableTrustworthyAI.github.io/#members>Members</a></li><li class=nav-item><a data-scroll href=https://ScalableTrustworthyAI.github.io/#publications>Publications</a></li><li class=nav-item><a data-scroll href=https://ScalableTrustworthyAI.github.io/#courses>Courses</a></li><li class=nav-item><a data-scroll href=https://ScalableTrustworthyAI.github.io/#openings>Openings</a></li><li class=nav-item><a data-scroll href=https://ScalableTrustworthyAI.github.io/#contact>Contact</a></li></ul></div></div></nav><header class=space-below><div class=header-content><div class=header-content-inner><h1>Scalable Trustworthy AI</h1><p class=slogan-text>Creating scalable and trustworthy AI with human guidance</p></div></div></header><section id=overview class=home-section><div class=container><div class=row style=display:flex;flex-wrap:wrap><div class="col-xs-12 col-md-4 section-heading"><h1 class=section-heading>Overview</h1></div></div><p><p>Artificial intelligence (AI) bears hope for a positive future for humanity. For example, AI could help us fight climate change by optimising power usage. Like fire and electricity have fundamentally changed the life of mankind (<a href="https://www.youtube.com/watch?v=sqd516M0Y5A">quote</a>), AI may also increase overall human productivity to balance out the ageing population and increase humanity&rsquo;s overall welfare.</p><p>The status quo is that AI is far from being perfect. One of the greatest issues is that <strong>AI systems are not trustworthy yet</strong>. It is difficult to understand when and why they fail. This is especially so when the models are deployed in environments that are different from the training environment (even slightly). Even worse, naive or malicious application of AI systems causes harm to humanity by amplifying political polarisation, by treating minority groups unfairly, and by jeopardising the human liberty and free will.</p><p>This leads to our study of <strong>Trustworthy AI</strong>. We aim to understand the trustworthiness of current AI systems and develop new technologies that enhance their trustworthiness. We focus on three sub-topics among other important topics:</p><ul><li><strong>Robustness</strong>: AI needs to generalise better to environments that are possibly different from the training environment.</li><li><strong>Uncertainty</strong>: AI needs to be aware of its own lack of knowledge and capabilities and communicate that with humans.</li><li><strong>Explainability</strong>: the mechanism behind AI&rsquo;s recognition and decisions needs to be understandable to humans.</li></ul><p>Fortunately, we are not alone in this effort. There are many other research labs around the world that make important contributions on Trustworthy AI. Our group find our uniqueness by striving for working solutions that are widely applicable and can be deployed at a large-scale. We thus name our group <strong>Scalable Trustworthy AI</strong>. To achieve the scalability, we commit ourselves to the following principles:</p><ul><li><strong>Simple is better than complex</strong>. Scalability and applicability are inversely correlated with complexity.</li><li><strong>Understand and then solve</strong>. You can only solve a problem when you understand it.</li><li><strong>Do not follow a dead end</strong>. When an approach is fundamentally limited in the long run, don&rsquo;t take it.</li></ul><p>With these principles in mind, we do research on <strong>Scalable Trustworthy AI</strong> technologies to guide the field to the right direction. We hope to contribute to mitigating the negative side-effects of AI and accelerating the AI-led advances for the future of humanity.</p><p>For prospective students: You might be interested in our internal curriculum and guidelines for a PhD program: <a href=https://github.com/coallaoh/Principles/tree/main/principles/phd>Principles for a PhD Program</a>.</p><p>STAI group is part of the <a href=https://tuebingen.ai/>Tübingen AI Center</a> and the <a href=https://uni-tuebingen.de/>University of Tübingen</a>. STAI is also within the ecosystem of International Max Planck Research School for Intelligent Systems (<a href=https://imprs.is.mpg.de/>IMPRS-IS</a>) and the <a href=https://ellis.eu/>ELLIS Society</a>.</p></p><div class="row logos-row"><div class="col-xs-3 affiliate-logos"><a href=https://tuebingen.ai/><img class=affiliate-logos src=img/tueai_logo_black_text.svg alt=logo></a></div><div class="col-xs-3 affiliate-logos"><a href=https://uni-tuebingen.de/><img class=affiliate-logos src=img/logo_uni_tue.svg alt=logo></a></div><div class="col-xs-3 affiliate-logos"><a href=https://imprs.is.mpg.de/><img class=affiliate-logos src=img/imprs_is_logo.png alt=logo></a></div><div class="col-xs-3 affiliate-logos"><a href=https://ellis.eu/><img class=affiliate-logos src=img/ellis_logo.png alt=logo></a></div></div></div></section><section id=members class=home-section><div class=container><div class=row><div class="col-xs-12 col-md-4 section-heading"><h1 class=section-heading>Members</h1></div></div><div class=row><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/joon/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/joon.png)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a></h2><h4>Group Leader</h4><ul class=social-icon-main-page><li><a href=mailto:coallaoh@gmail.com><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://twitter.com/coallaoh/><i class="fa fa-twitter small-icon" aria-hidden=true></i></a></li><li><a href="https://scholar.google.com/citations?user=kmXOOdsAAAAJ&amp;hl=en"><i class="ai ai-google-scholar small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/coallaoh/><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/seong-joon-oh-32113479/><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li></ul></div></div></div><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/elisa/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/elisa_pic.png)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/elisa/>Elisa Nguyen</a></h2><h4>PhD Student</h4><ul class=social-icon-main-page><li><a href=mailto:elisa.nguyen@live.de><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://twitter.com/_elinguyen><i class="fa fa-twitter small-icon" aria-hidden=true></i></a></li><li><a href="https://scholar.google.com/citations?user=YuBPap8AAAAJ&amp;hl=de"><i class="ai ai-google-scholar small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/ElisaNguyen><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/nguyen-elisa/><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li></ul></div></div></div><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/alex/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/alex.png)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/alex/>Alexander Rubinstein</a></h2><h4>PhD Student</h4><ul class=social-icon-main-page><li><a href=mailto:rubinshteyn.ar@phystech.edu><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/AlexanderRubinstein><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/alexander-rubinstein-043564116/><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li><li><a href=https://wa.me/79652404357><i class="fa fa-whatsapp small-icon" aria-hidden=true></i></a></li></ul></div></div></div><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/elif/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/elif.jpg)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/elif/>Elif Akata</a></h2><h4>PhD Student</h4><ul class=social-icon-main-page><li><a href=mailto:elif.akata@uni-tuebingen.de><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/eliaka><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/elifakata/><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li></ul></div></div></div><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/michael/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/michael.png)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/michael/>Michael Kirchhof</a></h2><h4>Collaborating PhD Student</h4><ul class=social-icon-main-page><li><a href=mailto:michael%20dot%20kirchhof%20at%20uni%20dash%20tuebingen%20dot%20de><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://twitter.com/mkirchhof_><i class="fa fa-twitter small-icon" aria-hidden=true></i></a></li><li><a href="https://scholar.google.com/citations?user=Xtgj8q0AAAAJ"><i class="ai ai-google-scholar small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/mkirchhof><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/michael-kirchhof/><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li></ul></div></div></div><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/balint/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/balint.png)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/balint/>Bálint Mucsányi</a></h2><h4>MSc Student</h4><ul class=social-icon-main-page><li><a href=mailto:balint%20dot%20mucsanyi%20at%20student%20dot%20uni%20dash%20tuebingen%20dot%20de><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://twitter.com/BalintMucsanyi><i class="fa fa-twitter small-icon" aria-hidden=true></i></a></li><li><a href="https://scholar.google.com/citations?hl=en&amp;user=NexA8EEAAAAJ"><i class="ai ai-google-scholar small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/bmucsanyi><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/b%C3%A1lint-mucs%C3%A1nyi-148a47222/><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li></ul></div></div></div><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/evgenii/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/evgenii.jpg)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/evgenii/>Evgenii Kortukov</a></h2><h4>MSc Student</h4><ul class=social-icon-main-page><li><a href=mailto:eekortukov%20at%20gmail%20dot%20com><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/kortukov/><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/eekortukov/><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li></ul></div></div></div><div class="col-xs-12 col-sm-3"><div id=profile><a href=https://ScalableTrustworthyAI.github.io/member/arnas/><div class=portrait itemprop=image style=background-image:url(https://ScalableTrustworthyAI.github.io/img//portraits/arnas.jpg)></div></a><div class=portrait-title><h2 itemprop=name><a href=https://ScalableTrustworthyAI.github.io/member/arnas/>Arnas Uselis</a></h2><h4>PhD Student</h4><ul class=social-icon-main-page><li><a href=mailto:arnas%20dot%20uselis%20at%20uni%20dash%20tuebingen%20dot%20de><i class="fa fa-envelope small-icon" aria-hidden=true></i></a></li><li><a href=https://twitter.com/a_uselis><i class="fa fa-twitter small-icon" aria-hidden=true></i></a></li><li><a href="https://scholar.google.com/citations?user=yNE5xM4AAAAJ&amp;hl=en&amp;oi=ao"><i class="ai ai-google-scholar small-icon" aria-hidden=true></i></a></li><li><a href=https://github.com/oshapio><i class="fa fa-github small-icon" aria-hidden=true></i></a></li><li><a href=https://www.linkedin.com/in/arnas-uselis-193883144><i class="fa fa-linkedin small-icon" aria-hidden=true></i></a></li></ul></div></div></div></div></div></section><section id=publications class=home-section><div class=container><div class=row><div class="col-xs-12 col-md-3 section-heading"><h1>Publications</h1></div><div class="col-xs-12 col-md-9"><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/kirchhof2023icml/><img src=https://ScalableTrustworthyAI.github.io/img/kirchhof2023icml.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/michael/>Michael Kirchhof</a>,</span>
<span class=author-name>Enkelejda Kasneci,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a></span></div></div><div class=pub-publication>ICML<div itemprop=datePublished>July, 2023</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2302.02865>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=https://github.com/mkirchhof/Probabilistic_Contrastive_Learning>Code</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/kirchhof2023icml.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/elisa2023arxiv/><img src=https://ScalableTrustworthyAI.github.io/img/elisa2023arxiv.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>A Bayesian Perspective On Training Data Attribution</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/elisa/>Elisa Nguyen</a>,</span>
<span class=author-name>Minjoon Seo,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a></span></div></div><div class=pub-publication>arXiv<div itemprop=datePublished>June, 2023</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2305.19765>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=https://github.com/elisanguyen/bayesian-tda>Code</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/elisa2023arxiv.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/elif2023arxiv/><img src=https://ScalableTrustworthyAI.github.io/img/elif2023arxiv.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>Playing repeated games with Large Language Models</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/elif/>Elif Akata</a>,</span>
<span class=author-name>Lion Schulz,</span>
<span class=author-name>Julian Coda-Forno,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a>,</span>
<span class=author-name>Matthias Bethge,</span>
<span class=author-name>Eric Schulz</span></div></div><div class=pub-publication>arXiv<div itemprop=datePublished>May, 2023</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2305.16867>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=https://github.com/naver-ai/NeglectedFreeLunch>Code</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/elif2023arxiv.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/han2023arxiv/><img src=https://ScalableTrustworthyAI.github.io/img/han2023arxiv.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name>Dongyoon Han*,</span>
<span class=author-name>Junsuk Choe*,</span>
<span class=author-name>Seonghyeok Chun,</span>
<span class=author-name>John Joon Young Chung,</span>
<span class=author-name>Minsuk Chang,</span>
<span class=author-name>Sangdoo Yun,</span>
<span class=author-name>Jean Y. Song,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a></span></div></div><div class=pub-publication>arXiv<div itemprop=datePublished>March, 2023</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2303.17595>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=https://github.com/naver-ai/NeglectedFreeLunch>Code</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/han2023arxiv.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/nam2022arxiv/><img src=https://ScalableTrustworthyAI.github.io/img/nam2022arxiv.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>Scratching Visual Transformer's Back with Uniform Attention</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name>Hyeon-Woo Nam,</span>
<span class=author-name>Yu-Ji Kim,</span>
<span class=author-name>Byeongho Heo,</span>
<span class=author-name>Dongyoon Han,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a>,</span>
<span class=author-name>Tae-Hyun Oh</span></div></div><div class=pub-publication>arXiv<div itemprop=datePublished>October, 2022</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2210.08457>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/nam2022arxiv.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/teney2022arxiv/><img src=https://ScalableTrustworthyAI.github.io/img/teney2022arxiv.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name>Damien Teney,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a>,</span>
<span class=author-name>Ehsan Abbasnejad</span></div></div><div class=pub-publication>arXiv<div itemprop=datePublished>September, 2022</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2209.00613>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/teney2022arxiv.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/chun2022eccv/><img src=https://ScalableTrustworthyAI.github.io/img/chun2022eccv.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>ECCV Caption: Correcting False Negatives by Collecting Machine-and-Human-verified Image-Caption Associations for MS-COCO</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name>Shanghyuk Chun,</span>
<span class=author-name>Wonjae Kim,</span>
<span class=author-name>Song Park,</span>
<span class=author-name>Minsuk Chang,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a></span></div></div><div class=pub-publication>ECCV<div itemprop=datePublished>To be published in October, 2022</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2204.03359>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=//github.com/naver-ai/eccv-caption>Code</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/chun2022eccv.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/kim2022icml/><img src=https://ScalableTrustworthyAI.github.io/img/kim2022icml.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>Dataset Condensation via Efficient Synthetic-Data Parameterization</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name>Jang-Hyun Kim,</span>
<span class=author-name>Jinuk Kim,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a>,</span>
<span class=author-name>Sangdoo Yun,</span>
<span class=author-name>Hwanjuk Song,</span>
<span class=author-name>Joonhyun Jeong,</span>
<span class=author-name>Jung-Woo Ha,</span>
<span class=author-name>Hyun Oh Song</span></div></div><div class=pub-publication>ICML<div itemprop=datePublished>July, 2022</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2205.14959>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=//github.com/snu-mllab/Efficient-Dataset-Condensation>Code</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/kim2022icml.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/lee2022cvpr/><img src=https://ScalableTrustworthyAI.github.io/img/lee2022cvpr.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name>Jungbeom Lee,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh</a>,</span>
<span class=author-name>Sangdoo Yun,</span>
<span class=author-name>Junsuk Choe,</span>
<span class=author-name>Eunji Kim,</span>
<span class=author-name>Sungroh Yoon</span></div></div><div class=pub-publication>CVPR<div itemprop=datePublished>June, 2022</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2203.03860>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=//github.com/naver-ai/w-ood>Code</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/lee2022cvpr.txt>Bibtex</a></div></div></div></div><div class=pub-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-4><a href=https://ScalableTrustworthyAI.github.io/publication/scimeca2022iclr/><img src=https://ScalableTrustworthyAI.github.io/img/scimeca2022iclr.png class=pub-banner itemprop=image></a></div><div class=col-sm-8><h3 class=article-title itemprop=name>Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective</h3><div class=pub-authors itemprop=author><div itemprop=author><span class=author-name>Luca Scimeca*,</span>
<span class=author-name><a href=https://ScalableTrustworthyAI.github.io/member/joon/>Seong Joon Oh*</a>,</span>
<span class=author-name>Sanghyuk Chun,</span>
<span class=author-name>Michael Poli,</span>
<span class=author-name>Sangdoo Yun</span></div></div><div class=pub-publication>ICLR<div itemprop=datePublished>April, 2022</div></div><div class=pub-links><a class="btn btn-primary btn-outline btn-xs" href=//arxiv.org/abs/2110.03095>PDF</a>
<a class="btn btn-primary btn-outline btn-xs" href=//coallaoh.github.io/data/scimeca2022iclr.txt>Bibtex</a></div></div></div></div></div></div></div></section><section id=courses class=home-section><div class=container><div class=row><div class="col-xs-12 col-md-3 section-heading"><h1>Courses</h1></div><div class="col-xs-12 col-md-9"><div class=course-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-12><h3 class=article-title itemprop=name><a href=https://ScalableTrustworthyAI.github.io/courses/tml_winter_2223/>Trustworthy Machine Learning @ University of Tübingen</a></h3><div class=course-date><div itemprop=datePublished>Winter Semester 2022-2023</div></div></div></div></div></div></div></div></section><section id=openings class=home-section><div class=container><div class=row><div class="col-xs-12 col-md-3 section-heading"><h1>Openings</h1></div><div class="col-xs-12 col-md-9"><div class=open-list-item itemscope itemtype=http://schema.org/CreativeWork><div class=row><div class=col-sm-12><h3 class=article-title itemprop=name>Postdoc Opportunity: Scalable Trustworthy AI - Novel Dataset Development</h3><div class=opening>We are seeking a highly motivated Postdoctoral Researcher to join our team at the University of Tübingen for an exciting two-year project on Scalable Trustworthy AI. The successful candidate will play a pivotal role in developing and collecting novel datasets that capture not only task outputs from human annotators but also valuable annotation byproducts, such as mouse traces, gaze patterns, click history, time to complete the task, and any corrections made during the process. Our goal is to leverage this rich data to better align AI systems with human cognitive mechanisms. Read the <a href=https://coallaoh.github.io/#han2023arxiv>Annotation Byproducts paper</a> for further details. This unique opportunity will allow the selected applicant to enhance their research expertise, contribute to cutting-edge advancements in AI, and benefit from Tübingen&rsquo;s vibrant research ecosystem and extensive international network. The position comes with a competitive postdoc salary and German social benefits. The starting date is flexible, and the selected candidate will be based at the Tübingen AI Center. We encourage candidates with a strong PhD degree in machine learning, natural language processing, computer vision, mathematics, statistics, human-computer interaction, or a related field to apply. To apply, please send your CV and research statement to <a href=mailto:coallaoh@gmail.com>coallaoh@gmail.com</a>.</div><div class=opening-date><div itemprop=datePublished>Posted: 3 March, 2023</div></div></div></div></div></div></div></div></section><section id=contact class=home-section><div class=container><div class=row><div class="col-xs-12 col-md-3 section-heading"><h1>Contact</h1></div><div class="col-xs-12 col-md-9"><ul class=list-unstyled><li><i class="fa fa-envelope fa-fw" aria-hidden=true></i>
<span>Seong Joon Oh: <a href=mailto:coallaoh@gmail.com>coallaoh@gmail.com</a></span></li><li><i class="fa fa-map-marker fa-fw" aria-hidden=true></i>
<span><a href=https://goo.gl/maps/VFTm4eaceQpN3Zib6>Maria-von-Linden-Straße 6, 72076 Tübingen, Germany</a></span></li></ul></div></div></div></section><footer class=site-footer><div class=container><p class=powered-by>© Seong Joon Oh, 2023 &#183;
Partially powered by the <a href=https://github.com/gcushen/hugo-academic target=_blank>Academic theme</a> for <a href=http://gohugo.io target=_blank>Hugo</a>.
<span class=pull-right><a href=#home id=back_to_top><span class=button_icon><i class="fa fa-chevron-up fa-2x" aria-hidden=true></i></span></a></span></p></div></footer><script src=//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js></script>
<script type=text/x-mathjax-config>
 MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
</script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script></body></html>