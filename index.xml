<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scalable Trustworthy AI</title><link>https://ScalableTrustworthyAI.github.io/</link><description>Recent content on Scalable Trustworthy AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&amp;copy; Seong Joon Oh, 2023</copyright><lastBuildDate>Tue, 25 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://ScalableTrustworthyAI.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts</title><link>https://ScalableTrustworthyAI.github.io/publication/han2023iccv/</link><pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/han2023iccv/</guid><description/></item><item><title>Scratching Visual Transformer's Back with Uniform Attention</title><link>https://ScalableTrustworthyAI.github.io/publication/nam2023iccv/</link><pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/nam2023iccv/</guid><description/></item><item><title>Arnas Uselis | PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/arnas/</link><pubDate>Mon, 24 Jul 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/arnas/</guid><description>I&amp;rsquo;m a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (IMPRS-IS), under the supervision of Seong Joon Oh.
I&amp;rsquo;m primarily interested in enhancing the generalization capabilities of current machine learning systems. This involves learning robust representations from raw data and using them in a way that accurately reflects data generative processes. I believe that mimicking the structure of the real-world in our models, both in how we learn representations and in how we use them, is a key part of making progress towards trustworthy systems.</description></item><item><title>Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023uaieai/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023uaieai/</guid><description/></item><item><title>URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023icml/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023icml/</guid><description/></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/evgenii/</link><pubDate>Sat, 17 Jun 2023 13:06:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/evgenii/</guid><description>I am currently pursuing my MSc degree in Machine Learning at the University of Tübingen, supervised by Seong Joon Oh, Elisa Nguyen and Alexander Rubinstein. My research interests primarily revolve around mitigating the risks associated with increasingly powerful ML systems. My current focus involves exploring data-driven explainability methods and their application to language models.
I receieved my Bachelor degree in Computer Science from Lomonosov Moscow State University in 2020. During and after my studies, I worked for about 2.</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/balint/</link><pubDate>Fri, 02 Jun 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/balint/</guid><description>I am a Machine Learning MSc student at the University of Tübingen, supervised by Seong Joon Oh, Michael Kirchhof, and Alexander Rubinstein.
I am interested in model architectures capable of representing different sources of uncertainty. My goal is to contribute to the theoretical foundations of uncertainty in machine learning while developing scalable practical solutions.
I received my BSc degree in Computer Science from ELTE Eötvös Loránd University in 2021 with the Outstanding Student of the Faculty award.</description></item><item><title>A Bayesian Perspective On Training Data Attribution</title><link>https://ScalableTrustworthyAI.github.io/publication/elisa2023neurips/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elisa2023neurips/</guid><description/></item><item><title>Playing repeated games with Large Language Models</title><link>https://ScalableTrustworthyAI.github.io/publication/elif2023arxiv/</link><pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elif2023arxiv/</guid><description/></item><item><title>Collaborating PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/michael/</link><pubDate>Fri, 31 Mar 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/michael/</guid><description>I&amp;rsquo;m a PhD student in the International Max-Planck Research School for Intelligent Systems (IMPRS-IS), co-supervised by Enkelejda Kasneci and Seong Joon Oh at the University of Tübingen.
My research goal is to make machine learning more trustworthy by delivering uncertainty estimates along with each prediction. To this end, I&amp;rsquo;m developing probabilistic embeddings that represent a model&amp;rsquo;s uncertainty directly in its embedding space. I love to understand and prove things first from a mathematical perspective (paper) and then scale them to large datasets in practice (paper).</description></item><item><title>Postdoc Opportunity: Scalable Trustworthy AI - Novel Dataset Development</title><link>https://ScalableTrustworthyAI.github.io/opening/postdoc-mar2023/</link><pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/opening/postdoc-mar2023/</guid><description/></item><item><title>Master Projects</title><link>https://ScalableTrustworthyAI.github.io/opening/thesis/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/opening/thesis/</guid><description/></item><item><title>PhD Students</title><link>https://ScalableTrustworthyAI.github.io/opening/phd/</link><pubDate>Mon, 05 Sep 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/opening/phd/</guid><description/></item><item><title>ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets</title><link>https://ScalableTrustworthyAI.github.io/publication/teney2023neurips/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/teney2023neurips/</guid><description/></item><item><title>ECCV Caption: Correcting False Negatives by Collecting Machine-and-Human-verified Image-Caption Associations for MS-COCO</title><link>https://ScalableTrustworthyAI.github.io/publication/chun2022eccv/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/chun2022eccv/</guid><description/></item><item><title>Dataset Condensation via Efficient Synthetic-Data Parameterization</title><link>https://ScalableTrustworthyAI.github.io/publication/kim2022icml/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kim2022icml/</guid><description/></item><item><title>Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data</title><link>https://ScalableTrustworthyAI.github.io/publication/lee2022cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/lee2022cvpr/</guid><description/></item><item><title>Group Leader</title><link>https://ScalableTrustworthyAI.github.io/member/joon/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/joon/</guid><description>My personal page is at seongjoonoh.com.
I am an independent group leader at the Tübingen AI Center at the University of Tübingen, where I lead the group on Scalable Trustworthy AI (STAI). I am interested in training reliable models (e.g. explainable, robust, and probabilistic models) and obtaining the necessary human supervision and guidance in a cost-effective way.
I have been a research scientist at NAVER AI Lab for 3.5 years. I received my PhD in computer vision and machine learning at Max-Planck Institute for Informatics in 2018, under the supervision of Bernt Schiele and Mario Fritz.</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/alex/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/alex/</guid><description>I am a PhD Student at the Tübingen AI Center at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (IMPRS-IS), where I work in the group on Scalable Trustworthy AI (STAI). I am interested in researching the ways of making models not only perfectly classify MNIST but also not fail too much on real world tasks. In case possibilities of some models are limited to academic datasets, I want to understand why that is the case.</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elif/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elif/</guid><description>I am a first year PhD student in the Scalable Trustworthy AI (STAI) group at the Tübingen AI Center.
I received my Master’s degree in Computer Science from University of Tübingen in 2022, and Bachelor’s in Computer Science from Saarland University in 2019. I am interested in understanding abstractions humans and neural networks perform in visual representations and how to use these to improve model robustness and Human-Computer Interaction.</description></item><item><title>Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective</title><link>https://ScalableTrustworthyAI.github.io/publication/scimeca2022iclr/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/scimeca2022iclr/</guid><description/></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elisa/</link><pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elisa/</guid><description>My personal page is at elisanguyen.github.io.
I am a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (IMPRS-IS). My research focus is on exploring training data attribution as a means of helping humans understand model behavior.
I absolved my Master’s in Interaction Technology at the University of Twente and my Bachelor’s in Computer Science and Management at the Nordakademie. I did my Bachelor studies in a dual study format in cooperation with Airbus, where I also worked for about 2.</description></item><item><title>Markdown ipsum</title><link>https://ScalableTrustworthyAI.github.io/post/post1/</link><pubDate>Tue, 12 Jul 2016 15:50:58 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/post/post1/</guid><description>Magorum notissima limite sua pars simus sumptis Incessit ignota coniunx serpunt Lorem markdownum ab cunas, semine commissus matrona manibusque plumis, nova sub Spartana loca ignibus. In partibus muneris, paludes rara, plectrumque, fontis, concubitus a locoque demptos exclamat conde ab aethera nihil.
Quamquam abit vulnere nec intus decidit clamor Nocuit quae tamen timent aperta Cervice preces totumque postquam nunc iacit sive Potestas te sis putaret sceleri totiens Retro profundo ad sede Iovem in este In ait flumina intrare Troiae Ut fatis praecordia alvum iamque, adeo tympana male silvas.</description></item><item><title/><link>https://ScalableTrustworthyAI.github.io/overview/overview/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/overview/overview/</guid><description>Artificial intelligence (AI) bears hope for a positive future for humanity. For example, AI could help us fight climate change by optimising power usage. Like fire and electricity have fundamentally changed the life of mankind (quote), AI may also increase overall human productivity to balance out the ageing population and increase humanity&amp;rsquo;s overall welfare.
The status quo is that AI is far from being perfect. One of the greatest issues is that AI systems are not trustworthy yet.</description></item><item><title>Trustworthy Machine Learning</title><link>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2223/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2223/</guid><description>Overview Goal Students will be able to critically read, assess, and discuss research work in Trustworthy Machine Learning (TML). Students will gain the technical background to implement basic TML techniques in a deep learning framework. Students will be ready to conduct their own research in TML and make contributions to the research community. Prerequisites Familiarity with Python and PyTorch coding. A pass grade from the Deep Learning Course (or equivalent). Basic knowledge of machine learning concepts.</description></item><item><title>Trustworthy Machine Learning</title><link>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2324/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2324/</guid><description>Overview Goal Students will be able to critically read, assess, and discuss research work in Trustworthy Machine Learning (TML). Students will gain the technical background to implement basic TML techniques in a deep learning framework. Students will be ready to conduct their own research in TML and make contributions to the research community. Prerequisites Familiarity with Python and PyTorch coding. A pass grade from the Deep Learning Course (or equivalent). Basic knowledge of machine learning concepts.</description></item></channel></rss>